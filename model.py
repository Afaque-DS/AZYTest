# -*- coding: utf-8 -*-
"""First_Model_Creation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZxuAm7a7SG7JL3gvx7ofTI6pXvNFRKvU
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import re

from sklearn.utils import resample

df2 = pd.read_csv('afzalpur.csv')

df2.head()

df = df2.drop(columns = ['age', 'address', 'provisional diagnosis', 'improvement status', 'complaints & duration'])

df.head()

df.shape

df.duration.unique()

inputs = age, gender, complaint, duration
result = treatment plan

combination of complaints
combination of treatments

# split complaints


print('first complaint : ', df['complaint'].loc[0])
print('first treatment plan : ',df['treatment plan/advised'].loc[0])

sadness            = REP-FORT, 4MG, 1-0-1, 1 Months, -OLAN, 10 MG, 1/2-0-1, 1 Months,
fear/palpititon    = REP-FORT, 4MG, 1-0-1, 1 Months, -OLAN, 10 MG, 1/2-0-1, 1 Months,
suspeciausness     = REP-FORT, 4MG, 1-0-1, 1 Months, -OLAN, 10 MG, 1/2-0-1, 1 Months,
hearning of voices = REP-FORT, 4MG, 1-0-1, 1 Months, -OLAN, 10 MG, 1/2-0-1, 1 Months,

second input = combination of complaint





# Function to clean the duration column
def clean_duration(duration):
    duration = str(duration).strip().lower()
    if duration.startswith('many'):  # If it starts with "many", assign it a value of 10
        return 10
    elif duration[0].isdigit():  # If the first character is a digit, extract the number
        # Extract the first number found in the string
        match = re.match(r'(\d+)', duration)
        return int(match.group(1)) if match else 0
    else:  # Default to 0 if no valid number or "many" is found
        return 0

# Apply the cleaning function to the duration column
df['duration_cleaned'] = df['duration'].apply(clean_duration)

# Handling complaints column by merging all complaints into a single string
df['complaint_cleaned'] = df['complaint'].str.lower()

df['treatment plan/advised'].unique()

df.head()

df.shape

df.gender.value_counts()

# Encode categorical column `gender`
le_gender = LabelEncoder()
df['gender_encoded'] = le_gender.fit_transform(df['gender'])

le_treatment = LabelEncoder()
df['treatment_encoded'] = le_treatment.fit_transform(df['treatment plan/advised'] )

# Step 2: Data augmentation to increase data volume
# Use resampling to increase the size of the dataset
augmented_df = resample(
    df,
    replace=True,
    n_samples=1000,  # Adjust this to the desired data volume
    random_state=42
)

# Step 3: Split data into features (X) and target (y)
X = augmented_df[['age_cleaned', 'gender_encoded', 'complaint_cleaned', 'duration_cleaned']]
y = augmented_df['treatment_encoded']  # Continuous target variable

# Step 4: Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Feature engineering
# Apply TfidfVectorizer to the `complaint_cleaned` column
tfidf_vectorizer = TfidfVectorizer(max_features=500)

# Combine preprocessing steps for all features
preprocessor = ColumnTransformer(
    transformers=[
        ('complaint_text', tfidf_vectorizer, 'complaint_cleaned'),
        ('numeric', StandardScaler(), ['age_cleaned', 'duration_cleaned']),
    ],
    remainder='passthrough'
)

# Step 6: Train a regression model
regressor = RandomForestRegressor(random_state=42)

# Preprocess the training data
X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# Fit the model
regressor.fit(X_train_transformed, y_train)

# Step 7: Evaluate the model
y_pred = regressor.predict(X_test_transformed)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared Score:", r2)

# Calculate standard regression metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = np.mean(np.abs(y_test - y_pred))

print("Mean Squared Error (MSE):", mse)
print("Mean Absolute Error (MAE):", mae)
print("R-squared Score (R²):", r2)

# Define a custom accuracy metric (e.g., predictions within ±10% of true values)
tolerance = 0.1  # 10% tolerance
y_test_array = np.array(y_test)
y_pred_array = np.array(y_pred)

within_tolerance = np.abs((y_pred_array - y_test_array) / y_test_array) <= tolerance
custom_accuracy = np.mean(within_tolerance) * 100  # Convert to percentage

print("Custom Accuracy (within ±10% of true values):", custom_accuracy, "%")

# Save the preprocessor and model
import pickle
with open("preprocessor.pkl", "wb") as f:
    pickle.dump(preprocessor, f)
with open("model.pkl", "wb") as f:
    pickle.dump(regressor, f)

# Save the LabelEncoders
with open("gender_encoder.pkl", "wb") as f:
    pickle.dump(le_gender, f)

with open("treatment_encoder.pkl", "wb") as f:
    pickle.dump(le_treatment, f)

# Step 8: Prediction on new data
def predict_treatment(new_data):
    new_data_transformed = preprocessor.transform(new_data)
    treatment_pred = regressor.predict(new_data_transformed)
    return treatment_pred

# Example usage
new_sample = pd.DataFrame({
    'age_cleaned': [30],
    'gender_encoded': [1],  # 1 for Female based on LabelEncoder
    'complaint_cleaned': ["sadness and fear"],
    'duration_cleaned': [5]
})
predicted_treatment = predict_treatment(new_sample)
print("Predicted Treatment Plan:", predicted_treatment)



df.head()

import json

column_name = 'complaint_cleaned'
complaints_json = {column_name: df[column_name].tolist()}

# Pretty-print the JSON
formatted_json = json.dumps(complaints_json, indent=4)

print("Generated JSON:")
print(formatted_json)

complaints_json

complaints_list = json.loads(complaints_json)  # Convert JSON string to Python list
formatted_json = json.dumps(complaints_list, indent=4)

formatted_json

import requests
from flask import Flask, jsonify
import pandas as pd
import threading
import json  # For JSON beautification

df.to_csv('afzalpur_encoded.csv', index = False)

# Initialize Flask app
app = Flask(__name__)

# Define the /getdata endpoint
@app.route('/getdata', methods=['GET'])
def fetch_data():
    # Load the data and analyze it
    df = pd.read_csv('/content/afzalpur_encoded.csv')
    complaints_json = {column_name: df['complaint_cleaned'].tolist()}

    # Pretty-print the JSON
    formatted_json = json.dumps(complaints_json, indent=4)

  # Update the file path if needed
    result = formatted_json

    # Beautify and return the JSON response
    pretty_json = json.dumps(result, indent=4)
    return app.response_class(pretty_json, mimetype='application/json')


# Function to run Flask in a thread
def run_flask():
    app.run(host='0.0.0.0', port=5221)


# Start Flask server in a new thread
thread = threading.Thread(target=run_flask)
thread.start()

# Test the API from the same Colab notebook
try:
    response = requests.get('http://127.0.0.1:5221/getdata')
    print("Beautified JSON Response:")
    print(json.dumps(response.json(), indent=4))  # Beautify the response
except Exception as e:
    print(f"Error: {e}")